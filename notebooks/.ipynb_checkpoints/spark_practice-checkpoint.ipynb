{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7716f025-1f6a-4eeb-82fc-ada7dfc23761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the container sql server\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkSQLServer\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7b11af-50d0-4ba5-957e-e8b811f4cb3b",
   "metadata": {},
   "source": [
    "## RDD Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50b5d13-f966-4f3a-b772-6ca82c767d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparkContext is used to create the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a6ba6e0-8cf7-41de-ad10-694de75bd986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "# Using sparkContext.parallelize()\n",
    "data = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "rdd1 = spark.sparkContext.parallelize(data)\n",
    "rdd1.count()\n",
    "rdd1.getNumPartitions()\n",
    "print(rdd1.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a1c603e-591d-4bca-8d27-b9aa019f3b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name,age,salary',\n",
       " 'manish,28,55000',\n",
       " 'ramesh,32,48000',\n",
       " 'rohan,26,61000',\n",
       " 'sapna,30,72000',\n",
       " 'shivani,27,68000']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create RDD from external Data source\n",
    "rdd2 = spark.sparkContext.textFile(\n",
    "    \"/opt/spark-data/input/data.csv\"\n",
    ")\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1e08fd16-0cd4-42ba-b10d-9906b586e9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SparkContext.emptyRDD of <SparkContext master=spark://spark-master:7077 appName=SparkSQLServer>>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create an empty RDD with no partition    \n",
    "rdd3 = spark.sparkContext.emptyRDD \n",
    "rdd3\n",
    "# Output:\n",
    "# rddString = spark.sparkContext.emptyRDD[String]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6bf41a73-baa5-474e-87f9-650f24da4bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name,age,salary',\n",
       " 'manish,28,55000',\n",
       " 'ramesh,32,48000',\n",
       " 'rohan,26,61000',\n",
       " 'sapna,30,72000',\n",
       " 'shivani,27,68000']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create RDD from external Data source\n",
    "rdd2 = spark.sparkContext.textFile(\n",
    "    \"/opt/spark-data/input/data.csv\"\n",
    ")\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a3562c-b444-4a48-b2fa-426a329a76e7",
   "metadata": {},
   "source": [
    "## Create Empty DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3c47f01-7ab5-4464-a28f-5ae0f807c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) create empty RDD\n",
    "emptyrdd= spark.sparkContext.emptyRDD()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91cafc20-5fc0-42c5-b2c7-9db0055baf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Create Empty DataFrame with Schema (StructType)\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "schema = StructType([\n",
    "           StructField('firstname', StringType(), True),\n",
    "           StructField('middlename', StringType(), True),\n",
    "           StructField('lastname', StringType(), True)\n",
    "           ])\n",
    "df1 = spark.createDataFrame(emptyrdd, schema)\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91d26396-12ed-42fe-9477-03974300e469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Convert Empty RDD to DataFrame\n",
    "df2 = emptyrdd.toDF(StructType([]))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "055a73dd-c267-4190-b231-5a2f5464f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create Empty DataFrame with Schema.\n",
    "df3 = spark.createDataFrame([],schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "32593702-f4ff-4d90-b8e6-0b226b39af21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Create Empty DataFrame without Schema (no columns)\n",
    "df4 = spark.createDataFrame([],StructType([]))\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121e273-0fe8-4d37-8975-b494b74fb432",
   "metadata": {},
   "source": [
    "## Convert PySpark Dataframe to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "deff598f-8ce1-41ee-a571-751332318ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/26 16:49:29 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- middle_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+----------+-----------+---------+-----+------+------+\n",
      "|first_name|middle_name|last_name|dob  |gender|salary|\n",
      "+----------+-----------+---------+-----+------+------+\n",
      "|James     |           |Smith    |36636|M     |60000 |\n",
      "|Michael   |Rose       |         |40288|M     |70000 |\n",
      "|Robert    |           |Williams |42114|      |400000|\n",
      "|Maria     |Anne       |Jones    |39192|F     |500000|\n",
      "|Jen       |Mary       |Brown    |     |F     |0     |\n",
      "+----------+-----------+---------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",60000),\n",
    "        (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",70000),\n",
    "        (\"Robert\",\"\",\"Williams\",\"42114\",\"\",400000),\n",
    "        (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",500000),\n",
    "        (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",0)]\n",
    "\n",
    "columns = [\"first_name\",\"middle_name\",\"last_name\",\"dob\",\"gender\",\"salary\"]\n",
    "pysparkDF = spark.createDataFrame(data = data, schema = columns)\n",
    "pysparkDF.printSchema()\n",
    "pysparkDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6f7e418f-b8a0-45ab-bc31-38f8294135eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>middle_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>dob</th>\n",
       "      <th>gender</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td></td>\n",
       "      <td>Smith</td>\n",
       "      <td>36636</td>\n",
       "      <td>M</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michael</td>\n",
       "      <td>Rose</td>\n",
       "      <td></td>\n",
       "      <td>40288</td>\n",
       "      <td>M</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert</td>\n",
       "      <td></td>\n",
       "      <td>Williams</td>\n",
       "      <td>42114</td>\n",
       "      <td></td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maria</td>\n",
       "      <td>Anne</td>\n",
       "      <td>Jones</td>\n",
       "      <td>39192</td>\n",
       "      <td>F</td>\n",
       "      <td>500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jen</td>\n",
       "      <td>Mary</td>\n",
       "      <td>Brown</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name middle_name last_name    dob gender  salary\n",
       "0      James                 Smith  36636      M   60000\n",
       "1    Michael        Rose            40288      M   70000\n",
       "2     Robert              Williams  42114         400000\n",
       "3      Maria        Anne     Jones  39192      F  500000\n",
       "4        Jen        Mary     Brown             F       0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandasDF = pysparkDF.toPandas()\n",
    "pandasDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588927c1-aec1-4ff0-90a6-5f4fe1e04694",
   "metadata": {},
   "source": [
    "## StructType & StructField with DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "121fecb4-3f85-4c3e-ac4a-19b67870a8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/30 11:08:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/30 11:08:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|id   |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])\n",
    " \n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe36e4-5a09-49c9-802d-74e32cb62750",
   "metadata": {},
   "source": [
    "###  PySpark Column Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a747cd2f-cc51-4ca3-bc68-da3823635dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|(col1 + col2)|\n",
      "+-------------+\n",
      "|          102|\n",
      "|          203|\n",
      "|          304|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 - col2)|\n",
      "+-------------+\n",
      "|           98|\n",
      "|          197|\n",
      "|          296|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 * col2)|\n",
      "+-------------+\n",
      "|          200|\n",
      "|          600|\n",
      "|         1200|\n",
      "+-------------+\n",
      "\n",
      "+-----------------+\n",
      "|    (col1 / col2)|\n",
      "+-----------------+\n",
      "|             50.0|\n",
      "|66.66666666666667|\n",
      "|             75.0|\n",
      "+-----------------+\n",
      "\n",
      "+-------------+\n",
      "|(col1 % col2)|\n",
      "+-------------+\n",
      "|            0|\n",
      "|            2|\n",
      "|            0|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col2 > col3)|\n",
      "+-------------+\n",
      "|         true|\n",
      "|        false|\n",
      "|        false|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col2 < col3)|\n",
      "+-------------+\n",
      "|        false|\n",
      "|         true|\n",
      "|        false|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|(col2 = col3)|\n",
      "+-------------+\n",
      "|        false|\n",
      "|        false|\n",
      "|         true|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[(100,2,1),(200,3,4),(300,4,4)]\n",
    "cols = [\"col1\",\"col2\",\"col3\"]\n",
    "df=spark.createDataFrame(data,cols)\n",
    "\n",
    "#Arthmetic operations\n",
    "df.select(df.col1 + df.col2).show()\n",
    "df.select(df.col1 - df.col2).show() \n",
    "df.select(df.col1 * df.col2).show()\n",
    "df.select(df.col1 / df.col2).show()\n",
    "df.select(df.col1 % df.col2).show()\n",
    "\n",
    "df.select(df.col2 > df.col3).show()\n",
    "df.select(df.col2 < df.col3).show()\n",
    "df.select(df.col2 == df.col3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b443d9c-09b3-4bf9-9dc6-51a8bc6406fb",
   "metadata": {},
   "source": [
    "### PySpark Column Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2639405c-88d9-4b50-8cd7-a9dc0b080246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=[(\"James\",\"Bond\",\"100\",None),\n",
    "      (\"Ann\",\"Varsa\",\"200\",'F'),\n",
    "      (\"Tom Cruise\",\"XXX\",\"400\",''),\n",
    "      (\"Tom Brand\",None,\"400\",'M')] \n",
    "columns=[\"fname\",\"lname\",\"id\",\"gender\"]\n",
    "df=spark.createDataFrame(data,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9920861-f248-4d57-ae9b-92bceb3db2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     James|     Bond|\n",
      "|       Ann|    Varsa|\n",
      "|Tom Cruise|      XXX|\n",
      "| Tom Brand|     NULL|\n",
      "+----------+---------+\n",
      "\n",
      "+--------------+\n",
      "|      fullName|\n",
      "+--------------+\n",
      "|    James,Bond|\n",
      "|     Ann,Varsa|\n",
      "|Tom Cruise,XXX|\n",
      "|          NULL|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.1 alias() – Set’s name to Column\n",
    "from pyspark.sql.functions import expr\n",
    "df.select(df.fname.alias(\"first_name\"), \\\n",
    "          df.lname.alias(\"last_name\")\n",
    "   ).show()\n",
    "\n",
    "#Another example\n",
    "df.select(expr(\" fname ||','|| lname\").alias(\"fullName\") \\\n",
    "   ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd643d98-fb8a-4a7b-9af6-07ede0a87844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|       Ann|Varsa|200|     F|\n",
      "|     James| Bond|100|  NULL|\n",
      "| Tom Brand| NULL|400|     M|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| NULL|400|     M|\n",
      "|     James| Bond|100|  NULL|\n",
      "|       Ann|Varsa|200|     F|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.2 asc() & desc() – Sort the DataFrame columns by Ascending or Descending order.\n",
    "df.sort(df.fname.asc()).show()\n",
    "df.sort(df.fname.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4c61497-aed7-4385-a27b-1f41978daa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.3 cast() & astype() – Used to convert the data Type.\n",
    "df.select(df.fname,df.id.cast(\"int\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d54179d-efe2-406c-9c51-92727f63faaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---+------+\n",
      "|fname|lname| id|gender|\n",
      "+-----+-----+---+------+\n",
      "|James| Bond|100|  NULL|\n",
      "|  Ann|Varsa|200|     F|\n",
      "+-----+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.4 between() – Returns a Boolean expression when a column values in between lower and upper bound.\n",
    "df.filter(df.id.between(100,300)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66bf430d-1de1-4223-90ef-2b652cf5a73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.5 contains() \n",
    "df.filter(df.fname.contains(\"Cruise\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3eb2652-b77c-4adc-8215-c24e39329f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+---+------+\n",
      "|    fname|lname| id|gender|\n",
      "+---------+-----+---+------+\n",
      "|Tom Brand| NULL|400|     M|\n",
      "+---------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  NULL|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.8 isNull & isNotNull() – Checks if the DataFrame column has NULL or non NULL values.\n",
    "df.filter(df.lname.isNull()).show()\n",
    "df.filter(df.lname.isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64b03950-96cf-415d-9745-ce15c77479e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[fname: string, lname: string, id: string]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.9 like() & rlike() – Similar to SQL LIKE expression\n",
    "\n",
    "#like , rlike\n",
    "df.select(df.fname,df.lname,df.id) \\\n",
    "  .filter(df.fname.like(\"%om\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98a88a50-74e4-4ed8-9c6c-140a4ebc6eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|substr|\n",
      "+------+\n",
      "|    Ja|\n",
      "|    An|\n",
      "|    To|\n",
      "|    To|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.10 substr() – Returns a Column after getting sub string from the Column\n",
    "df.select(df.fname.substr(1,2).alias(\"substr\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ae34a29-79ac-4b94-b6b9-1f7033621bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+\n",
      "|     fname|lname|new_gender|\n",
      "+----------+-----+----------+\n",
      "|     James| Bond|      NULL|\n",
      "|       Ann|Varsa|    Female|\n",
      "|Tom Cruise|  XXX|          |\n",
      "| Tom Brand| NULL|      Male|\n",
      "+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.11 when() & otherwise() – It is similar to SQL Case When, executes sequence of expressions until it matches the condition and returns a value when match.\n",
    "from pyspark.sql.functions import when\n",
    "df.select(df.fname,df.lname,when(df.gender==\"M\",\"Male\") \\\n",
    "              .when(df.gender==\"F\",\"Female\") \\\n",
    "              .when(df.gender==None ,\"\") \\\n",
    "              .otherwise(df.gender).alias(\"new_gender\") \\\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c8b4673-d03d-4832-95bd-20ded4a20113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------------------------------------------------------------+\n",
      "|     fname|CASE WHEN (gender = M) THEN Male WHEN (gender = F) THEN Female ELSE na END|\n",
      "+----------+--------------------------------------------------------------------------+\n",
      "|     James|                                                                        na|\n",
      "|       Ann|                                                                    Female|\n",
      "|Tom Cruise|                                                                        na|\n",
      "| Tom Brand|                                                                      Male|\n",
      "+----------+--------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.fname,expr(\"case when gender='M'then'Male' \" \" when gender='F' then 'Female' \" \" else 'na' end\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c034bdd-a8ae-4486-b3f8-e723eff7be67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d08a71d-55a7-49cc-a686-e942b60ffde8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43edee4e-2db9-41dd-b9e9-9266f1aecfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ec6c7-ccad-4c5b-93de-b4d1ac6c01fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ddfb16-c288-4fa2-91cf-c354701b2e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d227812a-7af8-48b6-bcfd-687df073e232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fa4342-9deb-43f0-8c85-9baa41377384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
